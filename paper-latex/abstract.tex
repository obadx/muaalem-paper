Assessing spoken language is challenging, and quantifying pronunciation metrics for machine learning models is even harder. However, for the Holy Quran, this task is enabled by the rigorous recitation rules (tajweed) established through the efforts of Muslim scholars, making highly effective assessment possible. Despite this advantage, scarcity of high-quality annotated data remains a significant barrier. In this work, we bridge these gaps by introducing: (1) A 98\% automated pipeline to produce high-quality Quranic datasets â€“ encompassing: Collection of recitations from expert reciters, Segmentation at pause points (waqf) using our fine-tuned wav2vec2-BERT model, Transcription of segments, Transcript verification via our novel Tasmeea algorithm; (2) 850+ hours of audio (~300K annotated utterances); (3) \textbf{qdat\_bench} benchmarks phonemes, diacritization, and Tajweed rules (Ghunnah, Qalqalah, Madd) on real recitation errors containing 159 samples; (4) A novel ASR-based approach for pronunciation error detection, utilizing our custom Quran Phonetic Script (QPS) to encode Tajweed rules (unlike the IPA standard for Modern Standard Arabic). QPS uses an 11-level script: (Phoneme level): Encodes Arabic letters with short/long vowels. (Sifat level): Encodes articulation characteristics of every phoneme. We further include comprehensive modeling with our novel multi-level CTC Model which achieved 0.21\% and 1.94\% average Phoneme Error Rate (PER) on the testset and qdat\_bench respectively, with 75.8\% Tajweed F1 score and 84.7\% accuracy on the benchmark. We release all code, data, and models as open-source: \href{https://obadx.github.io/quran-muaalem/en/}{https://obadx.github.io/quran-muaalem/en/}

