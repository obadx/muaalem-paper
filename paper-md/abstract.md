
Assessing spoken language is challenging, and quantifying pronunciation metrics for machine learning models is even harder. However, for the Holy Quran, this task is simplified by the rigorous recitation rules (Tajweed) established by Muslim scholars, enabling highly effective assessment. Despite this advantage, the scarcity of high-quality annotated data remains a significant barrier. In this work, we bridge these gaps by introducing: (1) A 98\% automated pipeline to produce high-quality Quranic datasets â€“ encompassing: Collection of recitations from expert reciters, Segmentation at pause points (waqf) using our fine-tuned wav2vec2-BERT model, Transcription of segments, Transcript verification via our novel Tasmeea algorithm; (2) 850+ hours of audio (~300K annotated utterances); (3) **qdat_bench**: the first of its kind bencmarking important Tajweed rules on real recitation errors; (4) A novel ASR-based approach for pronunciation error detection, utilizing our custom Quran Phonetic Script (QPS) to encode Tajweed rules (unlike the IPA standard for Modern Standard Arabic). QPS uses a 11-level script: (Phoneme level): Encodes Arabic letters with short/long vowels. The rest of levels (Sifat level): Encodes articulation characteristics of every phoneme. We further include comprehensive modeling with our novel multi-level CTC Model which achieved 0.20% and 2.2% average Phoneme Error Rate (PER) on the testset and qdat_bench respecivly. We release all code, data, and models as open-source: \href{https://obadx.github.io/prepare-quran-dataset/}{https://obadx.github.io/prepare-quran-dataset/}
